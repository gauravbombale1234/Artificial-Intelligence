{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-TzzYzYkUWF"
      },
      "source": [
        "**DCGAN - Deep Convolutional GAN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RCfb3YJbkRJR",
        "outputId": "791d0173-9743-4dcb-ae10-da8904843788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.11.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.26)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12.0)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12.0)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.44.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.13.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: wrapt, tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.16.0\n",
            "    Uninstalling wrapt-1.16.0:\n",
            "      Successfully uninstalled wrapt-1.16.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.15 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.15 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.17.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.12.0 which is incompatible.\n",
            "xarray 2024.9.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.12.0 numpy-1.23.5 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "462f5ea3117e4976a43143f526b097fb",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Importing the Libraries\n",
        "!pip install tensorflow==2.12.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JuLfAtXkoeHL",
        "outputId": "fc13fcc3-f517-486e-d3a6-4261dd8621f6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.12.0'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCdDMwLmpNSv"
      },
      "source": [
        "**Loading  and preprocessing the DataSet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUz_UIrRphN_"
      },
      "source": [
        "The left side of the assignment destructures the returned tuples from load_data().X_train: This is the training dataset containing the images of the handwritten digits. It will be a NumPy array of shape (60000, 28, 28) where 60,000 is the number of training samples, and 28x28 is the resolution of each image. y_train: This is the training labels corresponding to X_train. It contains the digit labels (0-9) for each image, with shape (60000). (,): This part is used to ignore the test data. The underscore () is a convention to signify that the value is being ignored. So, you're not storing X_test and y_test in this case.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3BszEYopL-a",
        "outputId": "7686290f-f2f3-4ce0-f15c-9dda18c22045"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC9Z_Gs7pMBR",
        "outputId": "0f5c2d50-1ef1-4e81-fc75-3edb029c7e31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ_GSN0upMD1",
        "outputId": "e60ed9dc-eb38-4881-d534-88a48ea629a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "28*28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGdGQLhXpMGx",
        "outputId": "010ef734-b005-48cd-c090-66eb1e4c40ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "bmUUfl-MpMJN",
        "outputId": "950ec2ec-617a-4500-b046-3ec46bd55269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "i=np.random.randint(0,60000)\n",
        "print(y_train[i])\n",
        "plt.imshow(X_train[i],cmap='gray');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8x6cDs5qd9s"
      },
      "outputs": [],
      "source": [
        "# Converting the Data into the float format\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype(\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I_yVbW7quaM",
        "outputId": "b231bf4e-497d-48ed-8aff-b83664c97484"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT0zrrHdrCWn",
        "outputId": "35da72be-3a4b-4203-f278-4ada34e3b842"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 255.0)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking the range of the data for Normalization\n",
        "X_train[0].min(), X_train[0].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zpni3MtQrP6Y"
      },
      "outputs": [],
      "source": [
        "# Normalize the Data\n",
        "X_train = (X_train - 127.5) / 127.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJVkX977rfDj",
        "outputId": "da75e8cb-4629-4975-a3ad-570277bb59e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(-1.0, 1.0)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0].min(), X_train[0].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SERNcR-1rmUl"
      },
      "outputs": [],
      "source": [
        "buffer_size = 60000\n",
        "batch_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8cFSy_zryu5",
        "outputId": "6fba0352-79e4-42a3-9806-1d6743d89eae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "234.375"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "buffer_size / batch_size  # mini batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obMN__cPr4me",
        "outputId": "2d18f1ae-db61-4022-a792-e1234d743a29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_pcmoYzr-13"
      },
      "outputs": [],
      "source": [
        "X_train=tf.data.Dataset.from_tensor_slices(X_train).shuffle(buffer_size).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNnY2YrbstDR"
      },
      "source": [
        "This code transforms X_train (which is typically a large dataset) into a tf.data.Dataset object, shuffles the data with a buffer size of buffer_size, and groups it into batches of size batch_size for efficient training. This is a typical preprocessing step before feeding data into a TensorFlow model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "TCuQJhXZsXMt",
        "outputId": "e6268d17-5b1a-461b-e37a-8bc56da866f8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>tensorflow.python.data.ops.batch_op._BatchDataset</b><br/>def __init__(input_dataset, batch_size, drop_remainder, name=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/batch_op.py</a>A `Dataset` that batches contiguous elements from its input.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 50);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "tensorflow.python.data.ops.batch_op._BatchDataset"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vk21rVt3s2au",
        "outputId": "76636bd9-dbf6-48a2-bf2f-a7b27e0cb3f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None)>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFlorhW8tJXr"
      },
      "outputs": [],
      "source": [
        "#100 -> 12544\n",
        "\n",
        "def build_generator():\n",
        "  network = tf.keras.Sequential()\n",
        "\n",
        "  network.add(layers. Dense (units = 7*7*256, use_bias= False, input_shape=(100,)))\n",
        "  network.add(layers.BatchNormalization())\n",
        "  network.add(layers. LeakyReLU())\n",
        "\n",
        "  network.add(layers. Reshape((7,7,256)))\n",
        "\n",
        "  # 7x7x128\n",
        "  network.add(layers.Conv2DTranspose(filters=128, kernel_size = (5,5), padding='same', strides=(2,2), use_bias=False))\n",
        "  network.add(layers.BatchNormalization())\n",
        "  network.add(layers.LeakyReLU())\n",
        "\n",
        "  # 14x14x64\n",
        "  network.add(layers.Conv2DTranspose(filters=64, kernel_size = (5,5), padding='same', strides=(2,2), use_bias=False))\n",
        "  network.add(layers.BatchNormalization())\n",
        "  network.add(layers.LeakyReLU())\n",
        "\n",
        "  # 28x28x1\n",
        "  network.add(layers.Conv2DTranspose(filters=1, kernel_size = (5,5), padding='same', strides=(2,2), use_bias=True, activation='tanh'))\n",
        "\n",
        "  network.summary()\n",
        "\n",
        "  return network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSy7EKjQyuAw",
        "outputId": "a882160e-a256-4971-c6f6-d60f9879076b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12544)             1254400   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 12544)            50176     \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 12544)             0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 14, 14, 128)      819200    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 14, 14, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 64)       204800    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 28, 28, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 56, 56, 1)        1601      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,330,945\n",
            "Trainable params: 2,305,473\n",
            "Non-trainable params: 25,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = build_generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpwZPVckzhWc",
        "outputId": "c7733958-3bf3-4930-a932-b2e36034cff9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'dense_input')>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generator.input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_E6FQ6yyzsj",
        "outputId": "f57b8af0-816d-4e7c-d895-fd046f88e6cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
              "array([[ 0.28464732,  1.6723169 ,  0.2403562 , -0.9389317 ,  0.49295473,\n",
              "        -0.94932824,  0.92141026,  0.70028216,  0.42925316,  1.2812542 ,\n",
              "        -0.5450141 ,  0.2540265 ,  2.150626  ,  1.1717647 , -0.83346653,\n",
              "        -0.01317661, -0.01008501, -0.9262376 ,  0.02503089,  0.31272426,\n",
              "        -0.4844633 , -0.94406486,  2.540205  ,  0.30743414, -0.07804174,\n",
              "         0.47923857, -0.14668782,  0.92752224,  0.76146036, -0.06720918,\n",
              "         1.1989766 ,  0.193221  ,  0.07535724,  0.81730443, -0.55667335,\n",
              "        -2.447123  , -0.37303758,  1.0216801 ,  1.1598657 ,  1.9240233 ,\n",
              "        -0.1842196 , -0.24072646,  2.7446394 , -0.9112393 , -0.01234921,\n",
              "         0.1092433 ,  0.8420447 , -0.766748  ,  0.22054048, -0.6647078 ,\n",
              "        -1.3106668 ,  1.027128  ,  0.04469293, -0.19392823, -0.34937167,\n",
              "        -0.3873018 ,  0.494377  ,  0.41571602,  0.2705907 , -1.3007131 ,\n",
              "        -0.12560272,  0.3378023 ,  1.00995   ,  0.86110234,  0.49588618,\n",
              "        -0.5994808 , -0.9743712 ,  0.37259954,  1.551568  ,  0.35525638,\n",
              "         0.18047562, -0.60240287,  0.9908608 , -1.4981085 ,  0.85296035,\n",
              "         1.1930538 ,  1.1217906 ,  0.3467449 ,  0.32496005,  0.461978  ,\n",
              "        -1.0747836 , -1.7116944 ,  2.3207338 , -0.6642934 , -0.9732218 ,\n",
              "         0.21491322, -0.13642114, -0.16716051, -0.9236053 ,  1.8610803 ,\n",
              "         0.05608458, -2.2247248 , -1.6261492 , -0.7106141 , -0.5714231 ,\n",
              "         0.23167586, -1.0885049 , -1.5276606 , -0.56153935, -0.00401677]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "noise = tf.random.normal([1,100])\n",
        "noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXm_1AuszrlM"
      },
      "outputs": [],
      "source": [
        "generated_image = generator(noise, training=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-vhzeGuz3mW",
        "outputId": "b27a5ce6-e432-4f33-cf68-8e4d57047c80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([1, 56, 56, 1])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "58leab2iz7Z-",
        "outputId": "140e5080-f3a5-4504-ac10-e08e116030c5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOvPErqF0peR"
      },
      "source": [
        "**Building the Discriminator**\n",
        "\n",
        "Dropout: https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\n",
        "Conv2d x Conv2dTranspose: https://stackoverflow.com/questions/68976745/in-keras-what-is-the-difference-between-conv2dtranspose-and-conv2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n-Fo3sQ0JNf"
      },
      "outputs": [],
      "source": [
        "def build_discriminator():\n",
        "  network = tf.keras.Sequential()\n",
        "\n",
        "  # 14x14x64\n",
        "  network.add(layers.Conv2D(filters=64, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=[56,56,1]))\n",
        "  network.add(layers.LeakyReLU())\n",
        "  network.add(layers.Dropout(0.3))\n",
        "\n",
        "  # 7x7x128\n",
        "  network.add(layers.Conv2D(filters=128, kernel_size=(5,5), strides=(2,2), padding='same'))\n",
        "  network.add(layers.LeakyReLU())\n",
        "  network.add(layers.Dropout(0.3))\n",
        "\n",
        "  network.add(layers.Flatten())\n",
        "  network.add(layers.Dense(1))\n",
        "\n",
        "  network.summary()\n",
        "\n",
        "  return network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPE1yAXF2nWr",
        "outputId": "333f0fee-1852-4004-bbca-fe25effea1f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6272"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "7*7*128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqKyHZRm3IY4",
        "outputId": "acc232e5-2d5e-4414-a7b7-25e8b63f4a19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 64)        1664      \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 128)       204928    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 25089     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 231,681\n",
            "Trainable params: 231,681\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator=build_discriminator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwmlbeJp3M2X",
        "outputId": "878c6ff6-c82e-4f12-f12f-8597c7f3eca7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 56, 56, 1) dtype=float32 (created by layer 'conv2d_input')>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "discriminator.input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsEenAo03eFG",
        "outputId": "6baf44c9-3732-4880-d838-b65366c0d813"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.00085488]], dtype=float32)>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "discriminator(generated_image, training=False) # logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r36tZGj3jyR",
        "outputId": "7fd2ac38-d999-4f34-cf1a-535d7acb730f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.50031686>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.sigmoid(0.00126728) # write the above value here for output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLEjimR24X13"
      },
      "source": [
        "**Error Calculations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBTNQ7VIrLMK"
      },
      "source": [
        "Logits: https://deepai.org/machine-learning-glossary-and-terms/logit\n",
        "\n",
        "This method quantifies how well the discriminator is able to distinguish real images from fakes images. It compares the discriminator predictions on real images with an array of 1s and the discriminator predictions on fake (generated) images with an array of Os."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnyYOhw_rmLg"
      },
      "outputs": [],
      "source": [
        "cross_entropy=tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tkEdmIfu_gH",
        "outputId": "adba70cc-65f1-416f-a62e-b88957507467"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.ones_like(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bO0LD3oNu_lx"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(expected_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(expected_output), expected_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd4QWZjHu_oI"
      },
      "outputs": [],
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DF72eNATu_q3"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=8.00001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wH2t-iZ0b6i"
      },
      "source": [
        "# **Training  the GAN and visualizing the resultsa**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY23aLHf00Ry"
      },
      "source": [
        "Based on: https://www.tensorflow.org/beta/tutorials/generative/dogan\n",
        "\n",
        "• @tf.function:\n",
        "https://www.tensorflow.org/guide/function#:~:text=You%20can%20use%20tf.is%20requi red%20to%20use%20SavedModel%20."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVDjySV9u_tr",
        "outputId": "81ee8f3e-110d-43a6-97f5-35f6511a8af2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None)>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEVhEPyWu_xB"
      },
      "outputs": [],
      "source": [
        "epochs=100\n",
        "noise_dimension=100\n",
        "number_of_images=16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfWlN2JTu_zx",
        "outputId": "dd03b8c6-84cb-4e12-f012-07d607f7bb8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(256, 100)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size, noise_dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zU9MBNBm2P1C"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "# This decorator tells Tensorflow to compile the function into a graph,\n",
        "# which improves performance by optimizing the execution,\n",
        "# especially on large datasets or when training over many iterations.\n",
        "def train(images):\n",
        "    noise = tf.random.normal([batch_size, noise_dimension])\n",
        "    # print(noise.shape)\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # tf.GradientTape(): TensorFlow's GradientTape is used to record operations\n",
        "        # for automatic differentiation. In this case, two tapes are used to\n",
        "        # separately track the computations for the generator (gen_tape)\n",
        "        # and discriminator (disc_tape).\n",
        "\n",
        "        # This is crucial because both networks need to be trained simultaneously but independently.\n",
        "\n",
        "        generated_images = generator(noise, training=True)\n",
        "        # Resize images before feeding them to the discriminator\n",
        "        images = tf.image.resize(images, [56, 56])\n",
        "        expected_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(expected_output, fake_output)\n",
        "\n",
        "        # generator (noise, training=True): The generator takes the random noise\n",
        "        # as input and produces generated_images. The training=True flag ensures\n",
        "        # that any training-specific behavior (like dropout) is activated.\n",
        "\n",
        "        # discriminator(images, training=True): The discriminator takes the real images from the\n",
        "        # dataset and produces expected_output, which is its prediction about the realness of the images.\n",
        "\n",
        "        # discriminator(generated_images, training=True): The discriminator also\n",
        "        # evaluates the generated_images produced by the generator and outputs\n",
        "        # fake_output, which is its prediction about the realness of the fake images.\n",
        "\n",
        "        generator_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "        # gen_tape.gradient: Computes the gradients of the gen_loss with respect to\n",
        "        # the generator's trainable variables (its weights and biases).\n",
        "        # These gradients will be used to update the generator.\n",
        "\n",
        "        # disc_tape.gradient: Computes the gradients of the disc_loss with respect\n",
        "        # to the discriminator's trainable variables.\n",
        "        # These gradients will be used to update the discriminator.\n",
        "\n",
        "        generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
        "\n",
        "        discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
        "\n",
        "        # generator_optimizer.apply_gradients: This applies the computed gradients\n",
        "        # to update the generator's parameters, using the generator optimizer.\n",
        "\n",
        "        # The zip(generator_gradients, generator.trainable_variables) pairs each gradient with the corresponding trainable variable.\n",
        "\n",
        "        # discriminator_optimizer.apply_gradients: Similarly, this updates the discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzhA-pys2QCT",
        "outputId": "cb4fcb5d-c3a7-422b-b348-494487070c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16, 100)\n"
          ]
        }
      ],
      "source": [
        "test_images = tf.random.normal([number_of_images, noise_dimension])\n",
        "print(test_images.shape)  # Outputs: TensorShape([16, 100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "JJMCMFEG5yM1",
        "outputId": "74db405a-004d-476f-a55a-e889d60e4c64"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nEager Execution in TensorFlow is a mode where operations are executed immediately, as if they were regular Python operations, \\nrather than being compiled into a computation graph. This is beneficial because it makes the code easier to read, debug, and allows \\nimmediate inspection of intermediate values during the execution of operations.\\n\\nWhy use tf.config.run_functions_eagerly(True)?\\nBy default, TensorFlow compiles code decorated with @tf.function into a computational graph for efficiency, which is optimal for \\nlarge-scale training and inference. However, when debugging or inspecting intermediate results (e.g., gradients, losses), this graph \\nmode can be difficult to work with.\\n\\nEnabling eager execution with tf.config.run_functions_eagerly(True) forces TensorFlow to run operations as regular Python code, even \\nfor functions decorated with @tf.function. This allows you to:\\n\\nStep through the code.\\nInspect variables at different points.\\nSee the immediate output of TensorFlow operations, making it ideal for debugging.\\n'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "X_train_batch = X_train.as_numpy_iterator().next()\n",
        "train(X_train_batch)\n",
        "\n",
        "# Purpose: This line configures Tensorflow to run functions eagerly,\n",
        "# even if they are decorated with @tf.function.\n",
        "'''\n",
        "Eager Execution in TensorFlow is a mode where operations are executed immediately, as if they were regular Python operations,\n",
        "rather than being compiled into a computation graph. This is beneficial because it makes the code easier to read, debug, and allows\n",
        "immediate inspection of intermediate values during the execution of operations.\n",
        "\n",
        "Why use tf.config.run_functions_eagerly(True)?\n",
        "By default, TensorFlow compiles code decorated with @tf.function into a computational graph for efficiency, which is optimal for\n",
        "large-scale training and inference. However, when debugging or inspecting intermediate results (e.g., gradients, losses), this graph\n",
        "mode can be difficult to work with.\n",
        "\n",
        "Enabling eager execution with tf.config.run_functions_eagerly(True) forces TensorFlow to run operations as regular Python code, even\n",
        "for functions decorated with @tf.function. This allows you to:\n",
        "\n",
        "Step through the code.\n",
        "Inspect variables at different points.\n",
        "See the immediate output of TensorFlow operations, making it ideal for debugging.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mn0xqyi_5_lH"
      },
      "outputs": [],
      "source": [
        "def train_gan(dataset, epochs, test_images):\n",
        "    for epoch in range(epochs):\n",
        "        #print(epoch)\n",
        "\n",
        "        for image_batch in dataset:\n",
        "            # print(image_batch.shape)\n",
        "            train(image_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bmwpBa8W7o7e",
        "outputId": "138cfa33-0dd9-4b70-e9a4-daeb5e7f7fa2"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-7f7b324a71f6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-d4d9e9d99d39>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(dataset, epochs, test_images)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;31m# print(image_batch.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_function_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"eager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-cba804ad7945>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mgenerator_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mdiscriminator_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    591\u001b[0m           data_format=data_format),\n\u001b[0;32m--> 592\u001b[0;31m       gen_nn_ops.conv2d_backprop_filter(\n\u001b[0m\u001b[1;32m    593\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1256\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Conv2DBackpropFilter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Example call:\n",
        "train_gan(X_train, epochs, test_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnsXHMqo95xY"
      },
      "source": [
        "dataset: The input dataset used for training, typically a set of images. epochs: The number of training iterations (how many times the model should go through the dataset), test_images: A set of test images used to generate output during the training process for visualizing the progress. Inside the epoch loop, another loop runs through each image_batch in the dataset. train(image_batch): This is a placeholder for the training function that handles training the GAN. After every epoch, it prints the current epoch number. generator(test_images, training=False): This calls the generator model with test_images to generate new images. The argument training=False indicates that the generator is in inference mode, so it won't apply training-related operations like dropout. fig = plt.figure(figsize=(10,10)): Creates a figure for"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKmx6smq7rEj"
      },
      "outputs": [],
      "source": [
        "def train_gan(dataset, epochs, test_images):\n",
        "    for epoch in range(epochs):\n",
        "        # print(epoch)\n",
        "\n",
        "        for image_batch in dataset:\n",
        "            # print(image_batch.shape)\n",
        "            train(image_batch)\n",
        "\n",
        "        print('Epoch: ', epoch + 1)\n",
        "\n",
        "        generated_images = generator(test_images, training=False)\n",
        "\n",
        "        fig = plt.figure(figsize=(10, 10))\n",
        "        for i in range(generated_images.shape[0]):\n",
        "            plt.subplot(4, 4, i + 1)\n",
        "            plt.imshow((generated_images[i, :, :, 0] * 127.5) + 127.5, cmap='gray')\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QMdL10Q-uhk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}